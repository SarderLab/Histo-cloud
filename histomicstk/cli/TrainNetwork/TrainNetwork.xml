<?xml version="1.0" encoding="UTF-8"?>
<executable>
  <category>HistomicsTK</category>
  <title>Train Segmentation Network</title>
  <description>Trains a neural network to segment structures from whole-slide image</description>
  <version>0.1.0</version>
  <documentation-url>https://github.com/SarderLab/deeplab-WSI</documentation-url>
  <license>Apache 2.0</license>
  <contributor>Brendon Lutnick (SUNY Buffalo)</contributor>
  <acknowledgements>This work is part of efforts in digital pathology by the Sarder Lab: SUNY Buffalo.</acknowledgements>
  <parameters>
    <label>IO</label>
    <description>Input/output parameters</description>
    <directory>
      <name>inputFolder</name>
      <label>Training Data Folder</label>
      <description>Select the folder containing the slides to be used for training</description>
      <channel>input</channel>
      <index>0</index>
    </directory>
    <file fileExtensions=".zip" reference="modelfiles">
      <name>output_model</name>
      <label>Output Model Name</label>
      <description>Select the name of the output model file produced. By default this willsaved in your Private folder.</description>
      <channel>output</channel>
      <index>1</index>
    </file>
    <string-vector>
      <name>classes</name>
      <longflag>classes</longflag>
      <label>Training layers</label>
      <description>A comma spearated list of the annotation layer names used for training. The name needs to match exactly. Layers will be built up from the annotations in order, sub-compartments should come after their parent structures.</description>
      <default>name1,name2,name3,etc</default>
    </string-vector>
    <file fileExtension=".zip" defaultNameMatch="^model.*.zip$" defaultPathMatch="^\/collection\/Segmentation models\/Glomeruli model\/">
      <name>inputModelFile</name>
      <label>Input Model File - (zip file)</label>
      <channel>input</channel>
      <index>1</index>
      <description>A zip file containing Tensorflow model-files and metadata for the deeplab segmentation network. This is used as a starting point for training using transfer learning.</description>
    </file>
  </parameters>
  <parameters advanced="true">
    <label>WSI Training Parameters</label>
    <description>Parameters for training a whole-slide image (WSI) segmentation algorythm</description>
    <integer>
      <name>patch_size</name>
      <label>Training tile size</label>
      <description>Tile size for randomly cropped WSI regions (pixels)</description>
      <longflag>patch_size</longflag>
      <default>400</default>
    </integer>
    <integer>
      <name>steps</name>
      <label>Training steps</label>
      <description>The number of steps used for network training. The network will see [steps * batch size] image patches during training</description>
      <longflag>steps</longflag>
      <default>10000</default>
    </integer>
    <integer>
      <name>batch_size</name>
      <label>Training batch size</label>
      <description>The batch size for training on WSI patches</description>
      <longflag>batch_size</longflag>
      <default>2</default>
    </integer>
    <integer>
      <name>num_clones</name>
      <label>GPU number of clones</label>
      <description>The number of GPUs used for training. (only change is multiple are available)</description>
      <longflag>num_clones</longflag>
      <default>1</default>
    </integer>
    <integer-vector>
      <name>WSI_downsample</name>
      <label>Training patch scale rates</label>
      <description>The downsampling (w.r.t full slide resolution) applied to the WSI patches durring extraction - durring training. The values passed will be randomly used durring the training. We find that prerformance improves if the network is shown multiple different WSI scales at training time.</description>
      <longflag>WSI_downsample</longflag>
      <default>1,2,3,4,5,6</default>
    </integer-vector>
    <double>
      <name>learning_rate</name>
      <label>Network learning rate</label>
      <description>The base learning rate used by the network. This will decay over the course of training.</description>
      <longflag>learning_rate</longflag>
      <default>0.0005</default>
    </double>
    <double>
      <name>learning_rate_start</name>
      <label>Slow start learning rate</label>
      <description>The initial learning rate used by the network. This should be set lower than the base learning rate to avoid shocking the model initially.</description>
      <longflag>learning_rate_start</longflag>
      <default>0.00001</default>
    </double>
    <integer>
      <name>slow_start_step</name>
      <label>Slow start steps</label>
      <description>The number of steps the network should be trained using the slow start learning rate.</description>
      <longflag>slow_start_step</longflag>
      <default>1000</default>
    </integer>
    <double>
      <name>augment</name>
      <label>Patch augmentation percent</label>
      <description>The percentage (as a decimal) of training patches that will be augmented by random color shifting and piecewise-affine transformations. Please enter a number between [0-1], a value of 0 will have no augmentation. Note - augmentation slows down network training and should be used sparingly!</description>
      <longflag>augment</longflag>
      <default>0.01</default>
    </double>
    <boolean>
      <name>batch_norm</name>
      <label>Fine tune batch norm layers</label>
      <longflag>batch_norm</longflag>
      <description>Fine tune the batch normalization layers - this should only be set to True if the batch size is sufficiently large. The official Deeplab implementation recommends a batch size > 12.</description>
      <default>false</default>
    </boolean>
    <boolean>
      <name>init_last_layer</name>
      <label>Use previous classifier.</label>
      <longflag>init_last_layer</longflag>
      <description>Use the pervious networks classification layer. An option to initialze the new model using the parameters from the previous models last layer (classification layer). This can only be used if them model contains the same number of layers as the previous model.</description>
      <default>false</default>
    </boolean>
    <boolean>
      <name>use_xml</name>
      <label>Train from existing XML.</label>
      <longflag>use_xml</longflag>
      <description>Use Aperio Imagescope XML style annotations for training without conversion to JSON layers. The XMLs should be uploaded to the training data folder.</description>
      <default>false</default>
    </boolean>
  </parameters>
  <parameters advanced="true">
    <label>Girder API URL and Key</label>
    <description>A Girder API URL and token for Girder client</description>
    <string>
      <name>girderApiUrl</name>
      <longflag>api-url</longflag>
      <label>Girder API URL</label>
      <description>A Girder API URL (e.g., https://girder.example.com:443/api/v1)</description>
      <default>https://athena.ccr.buffalo.edu/api/v1</default>
    </string>
    <string>
      <name>girderApiKey</name>
      <longflag>api-key</longflag>
      <label>Girder API Key</label>
      <description>A Girder token</description>
      <default>bbtEQX64TEi8kMWwbBlPzDkfifbSHGKBQI3YvYdu</default>
    </string>
  </parameters>
</executable>
